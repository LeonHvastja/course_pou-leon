[
["rvs.html", "Chapter 5 Multiple random variables 5.1 General properties and calculations 5.2 Bivariate distribution examples", " Chapter 5 Multiple random variables This chapter deals with multiple random variables and their distributions. The students are expected to acquire the following knowledge: Theoretical a R a 5.1 General properties and calculations Exercise 5.1 Let \\(X \\sim \\text{N}(0,1)\\) and \\(Y \\sim \\text{N}(0,1)\\) be independent random variables. Draw 1000 samples from \\((X,Y)\\) and plot a scatterplot. Now let \\(X \\sim \\text{N}(0,1)\\) and $Y | X = x N(ax, 1). Draw 1000 samples from \\((X,Y)\\) for \\(a = 1\\), \\(a=0\\), and \\(a=-0.5\\). Plot the scatterplots. How would you interpret parameter \\(a\\)? Plot the marginal distribution of \\(Y\\) for cases \\(a=1\\), \\(a=0\\), and \\(a=-0.5\\). Can you guess which distribution it is? set.seed(1) nsamps &lt;- 1000 x &lt;- rnorm(nsamps) y &lt;- rnorm(nsamps) ggplot(data.frame(x, y), aes(x = x, y = y)) + geom_point() y1 &lt;- rnorm(nsamps, mean = 1 * x) y2 &lt;- rnorm(nsamps, mean = 0 * x) y3 &lt;- rnorm(nsamps, mean = -0.5 * x) df &lt;- tibble(x = c(x,x,x), y = c(y1,y2,y3), a = c(rep(1, nsamps), rep(0, nsamps), rep(-0.5, nsamps))) ggplot(df, aes(x = x, y = y)) + geom_point() + facet_wrap(~a) + coord_equal(ratio=1) # Parameter a controls the scale of linear dependency between X and Y. ggplot(df, aes(x = y)) + geom_density() + facet_wrap(~a) Exercise 5.2 (Multinomial distribution) Let \\(X_i\\), \\(i = 1,...,k\\) represent \\(k\\) events, and \\(p_i\\) the probabilities of these events happening in a trial. Let \\(n\\) be the number of trials, and \\(X\\) a multivariate random variable, the collection of \\(X_i\\). Then \\(p(x) = \\frac{n!}{x_1!x_2!...x_k!} p_1^{x_1} p_2^{x_2}...p_k^{x_k}\\) is the PMF of a multinomial distribution. Show that the marginal distribution of \\(X_i\\) is a binomial distribution. Solution. We will approach this proof from the probabilistic point of view. W.L.O.G. let \\(x_1\\) be the marginal distribution we are interested in. The term \\(p^{x_1}\\) denotes the probability that event 1 happened \\(x_1\\) times. For this event not to happen, one of the other events needs to happen. So for each of the remaining trials, the probability of another event is \\(\\sum_{i=2}^k p_i = 1 - p_1\\), and there were \\(n - x_1\\) such trials. What is left to do is to calculate the number of permutations of event 1 happening and event 1 not happening. We choose \\(x_1\\) trials, from \\(n\\) trials. Therefore \\(p(x_1) = \\binom{n}{x_1} p_1^{x_1} (1 - p_1)^{n - x_1}\\), which is the binomial PMF. Interested students are encouraged to prove this mathematically. set.seed(1) 5.2 Bivariate distribution examples Exercise 5.3 (Discrete bivariate random variable) Let \\(X\\) represent the event that a die rolls an even number and let \\(Y\\) represent the event that a die rolls one, two, or a three. Find the marginal distributions of \\(X\\) and \\(Y\\). Find the PMF of \\((X,Y)\\). Find the CDF of \\((X,Y)\\). Find \\(P(X = 1 | Y = 1)\\). Solution. \\[\\begin{align} P(X = 1) = \\frac{1}{2} \\text{ and } P(X = 0) = \\frac{1}{2} \\\\ P(Y = 1) = \\frac{1}{2} \\text{ and } P(Y = 0) = \\frac{1}{2} \\\\ \\end{align}\\] \\[\\begin{align} P(X = 1, Y = 1) = \\frac{1}{6} \\\\ P(X = 1, Y = 0) = \\frac{2}{6} \\\\ P(X = 0, Y = 1) = \\frac{2}{6} \\\\ P(X = 0, Y = 0) = \\frac{1}{6} \\end{align}\\] \\[\\begin{align} P(X \\leq x, Y \\leq y) = \\begin{cases} \\frac{1}{6} &amp; x = 0, y = 0 \\\\ \\frac{3}{6} &amp; x \\neq y \\\\ 1 &amp; x = 1, y = 1 \\end{cases} \\end{align}\\] \\[\\begin{align} P(X = 1 | Y = 1) = \\frac{1}{3} \\end{align}\\] Exercise 5.4 (Continuous bivariate random variable) Let \\(p(x,y) = 6 (x - y)^2\\) be the PDF of a bivariate random variable \\((X,Y)\\), where both variables range from zero to one. Find CDF. Find marginal distributions. Find conditional distributions. R: Plot a grid of points and colour them by value â€“ this can help us visualize the PDF. R: Plot the marginal distribution of \\(Y\\) and the conditional distributions of \\(X | Y = y\\), where $y {0, 0.1, 0.5}. Solution. \\[\\begin{align} F(x,y) &amp;= \\int_0^{x} \\int_0^{y} 6 (t - s)^2 ds dt\\\\ &amp;= 6 \\int_0^{x} \\int_0^{y} t^2 - 2ts + s^2 ds dt\\\\ &amp;= 6 \\int_0^{x} t^2y - ty^2 + \\frac{y^3}{3} dt \\\\ &amp;= 6 (\\frac{x^3 y}{3} - \\frac{x^2y^2}{2} + \\frac{x y^3}{3}) \\\\ &amp;= 2 x^3 y - 3 t^2y^2 + 2 x y^3 \\end{align}\\] \\[\\begin{align} p(x) &amp;= \\int_0^{1} 6 (x - y)^2 dy\\\\ &amp;= 6 (x^2 - x + \\frac{1}{3}) \\\\ &amp;= 6x^2 - 6x + 2 \\end{align}\\] \\[\\begin{align} p(x) &amp;= \\int_0^{1} 6 (x - y)^2 dx\\\\ &amp;= 6 (y^2 - y + \\frac{1}{3}) \\\\ &amp;= 6y^2 - 6y + 2 \\end{align}\\] \\[\\begin{align} p(x|y) &amp;= \\frac{p(xy)}{p(y)} \\\\ &amp;= \\frac{6 (x - y)^2}{6 (y^2 - y + \\frac{1}{3})} \\\\ &amp;= \\frac{(x - y)^2}{y^2 - y + \\frac{1}{3}} \\end{align}\\] \\[\\begin{align} p(y|x) &amp;= \\frac{p(xy)}{p(x)} \\\\ &amp;= \\frac{6 (x - y)^2}{6 (x^2 - x + \\frac{1}{3})} \\\\ &amp;= \\frac{(x - y)^2}{x^2 - x + \\frac{1}{3}} \\end{align}\\] set.seed(1) # a get_pdf &lt;- function (x, y) { return ((x - y)^2) } x_axis &lt;- seq(0, 1, length.out = 100) y_axis &lt;- seq(0, 1, length.out = 100) df &lt;- expand.grid(x_axis, y_axis) colnames(df) &lt;- c(&quot;x&quot;, &quot;y&quot;) df &lt;- cbind(df, pdf = get_pdf(df$x, df$y)) ggplot(data = df, aes(x = x, y = y, color = pdf)) + geom_point() # b mar_pdf &lt;- function (x) { return (6 * x^2 - 6 * x + 2) } cond_pdf &lt;- function (x, y) { return (((x - y)^2) / (y^2 - y + 1/3)) } df &lt;- tibble(x = x_axis, mar = mar_pdf(x), y0 = cond_pdf(x, 0), y0.1 = cond_pdf(x, 0.1), y0.5 = cond_pdf(x, 0.5)) %&gt;% gather(dist, value, -x) ggplot(df, aes(x = x, y = value, color = dist)) + geom_line() Exercise 5.5 (Mixed bivariate random variable) Let \\(f(x,y) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)y!} x^{y+ \\alpha -1} e^{-x(1 + \\beta)}\\) be the PDF of a bivariate random variable, where \\(x \\in (0, \\infty)\\) and \\(y \\in \\mathbb{N}_0\\). Find the marginal distribution of \\(X\\). Do you recognize this distribution? Find the conditional distribution of \\(Y | X\\). Do you recognize this distribution? Calculate the probability \\(P(Y = 2 | X &lt; 5)\\) for \\((X,Y)\\). Find the marginal distribution of \\(Y\\). Do you recognize this distribution? R: Take 1000 random samples from \\((X,Y)\\) with parameters \\(\\beta = 1\\) and \\(\\alpha = 1\\). Plot a scatterplot. Plot a bar plot of the marginal distribution of \\(Y\\), and the theoretical PMF calculated from d) on the range from 0 to 10. Hint: Use the gamma function in R.? Solution. \\[\\begin{align} p(x) &amp;= \\sum_{k = 0}^{\\infty} \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)k!} x^{k + \\alpha -1} e^{-x(1 + \\beta)} &amp; \\\\ &amp;= \\sum_{k = 0}^{\\infty} \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)k!} x^{k} x^{\\alpha -1} e^{-x} e^{-\\beta x} &amp; \\\\ &amp;= \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} x^{\\alpha -1} e^{-\\beta x} \\sum_{k = 0}^{\\infty} \\frac{1}{k!} x^{k} e^{-x} &amp; \\\\ &amp;= \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} x^{\\alpha -1} e^{-\\beta x} &amp; \\text{the last term above sums to one -- Poisson PMF} \\end{align}\\] This is the Gamma PDF. \\[\\begin{align} p(y|x) &amp;= \\frac{p(x,y)}{p(x)} \\\\ &amp;= \\frac{f(x,y) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)y!} x^{y+ \\alpha -1} e^{-x(1 + \\beta)}}{\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} x^{\\alpha -1} e^{-\\beta x}} \\\\ &amp;= \\frac{x^y e^{-x}}{y!}. \\end{align}\\] This is the Poisson PMF. \\[\\begin{align} P(Y = 2 | X = 2.5) = \\frac{2.5^2 e^{-2.5}}{2!} \\approx 0.26. \\end{align}\\] \\[\\begin{align} p(y) &amp;= \\int_{0}^{\\infty} \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)y!} x^{y + \\alpha -1} e^{-x(1 + \\beta)} dx &amp; \\\\ &amp;= \\frac{1}{y!} \\int_{0}^{\\infty} \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} x^{(y + \\alpha) -1} e^{-(1 + \\beta)x} dx &amp; \\\\ &amp;= \\frac{1}{y!} \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\int_{0}^{\\infty} \\frac{\\Gamma(y + \\alpha)}{(1 + \\beta)^{y + \\alpha}} \\frac{(1 + \\beta)^{y + \\alpha}}{\\Gamma(y + \\alpha)} x^{(y + \\alpha) -1} e^{-(1 + \\beta)x} dx &amp; \\text{we add the term so that we have Gamma PDF inside the integral} \\\\ &amp;= \\frac{1}{y!} \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\frac{\\Gamma(y + \\alpha)}{(1 + \\beta)^{y + \\alpha}}. \\end{align}\\] We do not recognize this distribution. set.seed(1) px &lt;- function (x, alpha, beta) { return((1 / factorial(x)) * (beta^alpha / gamma(alpha)) * (gamma(x + alpha) / (1 + beta)^(x + alpha))) } nsamps &lt;- 1000 rx &lt;- rgamma(nsamps, 1, 1) ryx &lt;- rpois(nsamps, rx) ggplot(data = data.frame(x = rx, y = ryx), aes(x = x, y = y)) + geom_point() ggplot(data = data.frame(x = rx, y = ryx), aes(x = y)) + geom_bar(aes(y = (..count..)/sum(..count..))) + stat_function(fun = px, args = list(alpha = 1, beta = 1), color = &quot;red&quot;) Exercise 5.6 Let \\(f(x,y) = cx^2y\\) for \\(x^2 \\leq y \\leq 1\\) and zero otherwise. Find such \\(c\\) that \\(f\\) is a PDF of a bivariate random variable. This exercise is borrowed from Wasserman. Solution. \\[\\begin{align} 1 &amp;= \\int_{-1}^{1} \\int_{x^2}^1 cx^2y dy dx \\\\ &amp;= \\int_{-1}^{1} cx^2 (\\frac{1}{2} - \\frac{x^4}{2}) dx \\\\ &amp;= \\frac{c}{2} \\int_{-1}^{1} x^2 - x^6 dx \\\\ &amp;= \\frac{c}{2} (\\frac{1}{3} + \\frac{1}{3} - \\frac{1}{7} - \\frac{1}{7}) \\\\ &amp;= \\frac{c}{2} \\frac{8}{21} \\\\ &amp;= \\frac{4c}{21} \\end{align}\\] It follows \\(c = \\frac{21}{4}\\). "]
]
